{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "# Lets build a real-time translator in the browser!\n",
    "\n",
    "## What is NodeJS?\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*WVP8haZ_BXxVPEzsPDZWsQ.png \"Logo Title Text 1\")\n",
    "\n",
    "- Node.js is a JavaScript run-time environment. \n",
    "- It includes everything you need to execute a program written in JavaScript.\n",
    "- Java analogy time!\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/1*sYPllpcAZLHmpuQSRPuO0Q.png \"Logo Title Text 1\")\n",
    "\n",
    "- javascript used to only be able to run in your browser\n",
    "- now it can run on your machine as a standalone application\n",
    "- Both your browser JavaScript and Node.js run on the V8 JavaScript runtime engine. \n",
    "- This converts JS to machine code \n",
    "- It uses an event-driven, non-blocking I/O model that makes it lightweight and efficient.\n",
    "- I/O refers to input/output. \n",
    "- It can be anything ranging from reading/writing local files to making an HTTP request to an API.\n",
    "- I/O takes time and hence blocks other functions.\n",
    "- Blocking vs nonblocking IO? See this \n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/1*B_UCsFOPfRDKO8ovHpxphg.png \"Logo Title Text 1\")\n",
    "\n",
    "-  The javascript event loop allows for non-blocking io!\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/1*BBlPbUjGVtfSPd7BHa1LHw.png \"Logo Title Text 1\")\n",
    "\n",
    "- NPM (Node Package Manager) easily helps install node packages\n",
    "\n",
    "\n",
    "## How Does Machine Translation Work? \n",
    "\n",
    "Here is our input + output data\n",
    "\n",
    "```javascript\n",
    "Go.\t\tVa !\n",
    "Run!\tCours !\n",
    "Run!\tCourez !\n",
    "Wow!\tÇa alors !\n",
    "Fire!\tAu feu !\n",
    "Help!\tÀ l'aide !\n",
    "Jump.\tSaute.\n",
    "Stop!\tÇa suffit !\n",
    "Stop!\tStop !\n",
    "Stop!\tArrête-toi !\n",
    "```\n",
    "\n",
    "Input Sequences: Padded to a maximum length of 16 characters with a vocabulary of 71 different characters (10000, 16, 71).\n",
    "Output Sequences: Padded to a maximum length of 59 characters with a vocabulary of 93 different characters (10000, 59, 93).\n",
    "\n",
    "```javascript\n",
    "Input1: [‘G’, ‘o’, ‘.’, ”]\n",
    "Input2: [ ”, ‘V’, ‘a’, ‘ ‘]\n",
    "Output: [‘V’, ‘a’, ‘ ‘, ‘!’]\n",
    "```\n",
    "\n",
    "\n",
    "### Encoder-Decoder Architecture\n",
    "\n",
    "![alt text](https://www.researchgate.net/profile/Dennis_Gannon/publication/296705493/figure/fig1/AS:335984429420545@1457116338082/A-sequence-to-sequence-RNN-English-to-French-translator-with-the-encoder-and-decoder.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- The encoder is responsible for outputting a fixed-length encoding of the input English sequence, \n",
    "- The decoder is responsible for predicting the output sequence, one character per output time step.\n",
    "- Both are LSTM networks\n",
    "\n",
    "![alt text](https://blog.keras.io/img/seq2seq/seq2seq-teacher-forcing.png \"Logo Title Text 1\")\n",
    "\n",
    "### LSTMS? Long short temr memory networks \n",
    "\n",
    "- input, output, and forget gates\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/0*LyfY3Mow9eCYlj7o. \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "### Training \n",
    "\n",
    "- Step 1 - Turn the sentences into 3 Numpy arrays, encoder_input_data, decoder_input_data, decoder_target_data\n",
    "- Step 2 - Create 2 LSTM networks. \n",
    "- Step 3 - Feed first LSTM the vectorized english input\n",
    "- Step 4 - Use the learned hidden states to intialize the 2nd LSTMs hidden state\n",
    "- Step 5 - Feed the second LSTM the vectorized french pair\n",
    "- Step 6 - Have the decoder make a prediction for every char. Use the associated french phrase as the target\n",
    "- Step 7 - Backpropagate error\n",
    "- Step 8 - Repeat for as many datapoints\n",
    "\n",
    "About 1 hour of training on a Macbook CPU\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/2000/1*1I2tTjCkMHlQ-r73eRn4ZQ.png \"Logo Title Text 1\")\n",
    "\n",
    "### Inference\n",
    "- Step 1 Encode the input sentence and retrieve the initial decoder state\n",
    "- Step 2Run one step of the decoder with this initial state and a \"start of sequence\" token as target. The output will be the next target character.\n",
    "- Step 3 Append the target character predicted and repeat.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
